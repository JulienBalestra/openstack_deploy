heat_template_version: 2014-10-16

description: >
  Fleet instance with role=worker

resources:
  random:
    type: OS::Heat::RandomString
    properties:
      length: 10
      sequence: lettersdigits

  port:
    depends_on: [ random ]
    type: OS::Neutron::Port
    properties:
      name:
        str_replace:
          template: bn%-rand%
          params:
            "bn%": { get_param: instance_basename }
            "rand%": { get_attr: [random, value] }
      network_id: { get_param: network }
      fixed_ips: [{ "subnet_id": { get_param: subnet } }]
      security_groups: [ { get_param: security_group } ]

  floating:
    type: OS::Neutron::FloatingIP
    depends_on: [ port ]
    properties:
      floating_network: { get_param: floatingip_network_name }
      port_id: { get_resource: port }

  instance:
    depends_on: [ port ]
    type: OS::Nova::Server
    properties:
      name:
        str_replace:
          template: bn%-rand%
          params:
            "bn%": { get_param: instance_basename }
            "rand%": { get_attr: [random, value] }
      user_data_format: RAW
      user_data: { get_resource: userdata }
      key_name: { get_param: key_name }
      image: { get_param: image }
      flavor: { get_param: flavor }
      networks:
        - port: { get_resource: port }
      scheduler_hints:
        group: { get_param: anti_affinity }

      metadata:
        etcd_initial_cluster: { get_param: etcd_initial_cluster }
        fleet_state: { get_param: fleet_state }

  userdata:
    type: OS::Heat::CloudConfig
    properties:
      cloud_config:
        preserve_hostname: false
        manage_etc_hosts: true

        write_files:
          - path: /opt/bin/setup-etcd2-environment
            permissions: 0755
            content: |
              #!/usr/bin/env bash

              set -e ; set -o pipefail

              DEFAULT_IPV4=$(curl 169.254.169.254/1.0/meta-data/local-ipv4)

              cat << EOF | tee /etc/etcd2-environment
              ETCD_PROXY="on"
              ETCD_INITIAL_CLUSTER="$(curl http://169.254.169.254/openstack/latest/meta_data.json |
                jq -r -e .meta.etcd_initial_cluster)"
              ETCD_ADVERTISE_CLIENT_URLS="http://${DEFAULT_IPV4}:2379"
              ETCD_LISTEN_CLIENT_URLS="http://0.0.0.0:2379,http://0.0.0.0:4001"
              ETCD_LISTEN_PEER_URLS="http://${DEFAULT_IPV4}:2380,http://${DEFAULT_IPV4}:7001"
              EOF

          - path: /opt/bin/setup-fleet-environment
            permissions: 0755
            content: |
              #!/usr/bin/env bash

              set -e ; set -o pipefail

              cat << EOF | tee /etc/fleet-environment
              FLEET_METADATA="state=$(curl http://169.254.169.254/openstack/latest/meta_data.json |
                jq -r -e .meta.fleet_state),role=kube"
              EOF

              set +e

              for i in {0..10}
              do
                sleep $i
                etcdctl cluster-health && break
              done

          - path: /opt/bin/kubelet-wrapper
            permissions: 0755
            content: |
              #!/bin/bash
              # Wrapper for launching kubelet via rkt-fly stage1.
              #
              # Make sure to set KUBELET_VERSION to an image tag published here:
              # https://quay.io/repository/coreos/hyperkube?tab=tags Alternatively,
              # override $KUBELET_ACI to a custom location.

              set -e

              if [ -z "${KUBELET_VERSION}" ]; then
                  echo "ERROR: must set KUBELET_VERSION"
                  exit 1
              fi

              KUBELET_ACI="${KUBELET_ACI:-quay.io/coreos/hyperkube}"

              mkdir --parents /etc/kubernetes
              mkdir --parents /var/lib/docker
              mkdir --parents /var/lib/kubelet
              mkdir --parents /run/kubelet

              exec /usr/bin/rkt run \
                --volume etc-kubernetes,kind=host,source=/etc/kubernetes \
                --volume etc-ssl-certs,kind=host,source=/usr/share/ca-certificates \
                --volume var-lib-docker,kind=host,source=/var/lib/docker \
                --volume var-lib-kubelet,kind=host,source=/var/lib/kubelet \
                --volume os-release,kind=host,source=/usr/lib/os-release \
                --volume run,kind=host,source=/run \
                --mount volume=etc-kubernetes,target=/etc/kubernetes \
                --mount volume=etc-ssl-certs,target=/etc/ssl/certs \
                --mount volume=var-lib-docker,target=/var/lib/docker \
                --mount volume=var-lib-kubelet,target=/var/lib/kubelet \
                --mount volume=os-release,target=/etc/os-release \
                --mount volume=run,target=/run \
                --trust-keys-from-https \
                $RKT_OPTS \
                --stage1-from-dir=stage1-fly.aci \
              ${KUBELET_ACI}:${KUBELET_VERSION} --exec=/kubelet -- "$@"

          - path: /etc/systemd/system/confd@.service
            permissions: 0644
            content: |
              [Unit]
              Description=kube apiserver

              [Service]
              Environment=KUBELET_VERSION=v1.3.0_coreos.0
              EnvironmentFile=/etc/network-environment
              Type=oneshot
              ExecStart=/usr/bin/confd -onetime -confdir=/etc/kubernetes/conf -config-file=%i.toml

          - path: /etc/systemd/system/kubelet.service
            permissions: 0644
            content: |
              [Unit]
              Description=Kubelet

              After=confd@kube-apiserver.service
              After=confd@kube-controller-manager.service
              After=confd@kube-proxy.service
              After=confd@kube-scheduler.service

              [Service]
              Environment=KUBELET_VERSION=v1.3.0_coreos.0
              EnvironmentFile=/etc/network-environment
              ExecStartPre=/usr/bin/mkdir -p /etc/kubernetes/manifests

              ExecStart=/opt/bin/kubelet-wrapper \
                --api-servers=http://127.0.0.1:8080 \
                --network-plugin-dir=/etc/rkt/net.d \
                --register-schedulable=false \
                --allow-privileged=true \
                --config=/etc/kubernetes/manifests \
                --hostname-override=${DEFAULT_IPV4} \
                --cluster-dns=${DEFAULT_IPV4} \
                --cluster-domain=skydns.local \
                --container-runtime=rkt

          - path: /etc/kubernetes/conf/conf.d/kube-apiserver.toml
            permissions: 0644
            content: |
              [template]
              src = "kube-apiserver.tmpl"
              dest = "/etc/kubernetes/manifests/kube-apiserver.yaml"
              owner = "root"
              mode = "0644"

          - path: /etc/kubernetes/conf/templates/kube-apiserver.tmpl
            permissions: 0644
            content: |
              apiVersion: v1
              kind: Pod
              metadata:
                name: kube-apiserver
                namespace: kube-system
              spec:
                hostNetwork: true
                containers:
                - name: kube-apiserver
                  image: quay.io/coreos/hyperkube:{{getenv "TAG"}}
                  command:
                  - /hyperkube
                  - apiserver
                  - --bind-address=0.0.0.0
                  - --etcd-servers={{getenv "ETCD_ENDPOINTS"}}
                  - --allow-privileged=true
                  - --service-cluster-ip-range={{getenv "SERVICE_IP_RANGE"}}
                  - --advertise-address={{getenv "DEFAULT_IPV4"}}
                  - --admission-control=NamespaceLifecycle,LimitRanger,ServiceAccount,ResourceQuota
                  - --runtime-config=extensions/v1beta1=true,extensions/v1beta1/thirdpartyresources=true
                  - --container-runtime=rkt
                  ports:
                  - containerPort: 8080
                    hostPort: 8080
                    name: local

          - path: /etc/kubernetes/conf/conf.d/kube-controller-manager.toml
            permissions: 0644
            content: |
              [template]
              src = "kube-controller-manager.tmpl"
              dest = "/etc/kubernetes/manifests/kube-controller-manager.yaml"
              owner = "root"
              mode = "0644"

          - path: /etc/kubernetes/conf/templates/kube-controller-manager.tmpl
            permissions: 0644
            content: |
              apiVersion: v1
              kind: Pod
              metadata:
                name: kube-controller-manager
                namespace: kube-system
              spec:
                hostNetwork: true
                containers:
                - name: kube-controller-manager
                  image: quay.io/coreos/hyperkube:{{getenv "TAG"}}
                  command:
                  - /hyperkube
                  - controller-manager
                  - --master=http://127.0.0.1:8080
                  - --leader-elect=true
                  livenessProbe:
                    httpGet:
                      host: 127.0.0.1
                      path: /healthz
                      port: 10252
                    initialDelaySeconds: 15
                    timeoutSeconds: 1

          - path: /etc/kubernetes/conf/conf.d/kube-proxy.toml
            permissions: 0644
            content: |
              [template]
              src = "kube-proxy.tmpl"
              dest = "/etc/kubernetes/manifests/kube-proxy.yaml"
              owner = "root"
              mode = "0644"

          - path: /etc/kubernetes/conf/templates/kube-proxy.tmpl
            permissions: 0644
            content: |
              apiVersion: v1
              kind: Pod
              metadata:
                name: kube-proxy
                namespace: kube-system
              spec:
                hostNetwork: true
                containers:
                - name: kube-proxy
                  image: quay.io/coreos/hyperkube:{{getenv "TAG"}}
                  command:
                  - /hyperkube
                  - proxy
                  - --master=http://127.0.0.1:8080
                  - --proxy-mode=iptables
                  securityContext:
                    privileged: true

          - path: /etc/kubernetes/conf/conf.d/kube-scheduler.toml
            permissions: 0644
            content: |
              [template]
              src = "kube-scheduler.tmpl"
              dest = "/etc/kubernetes/manifests/kube-scheduler.yaml"
              owner = "root"
              mode = "0644"

          - path: /etc/kubernetes/conf/templates/kube-scheduler.tmpl
            permissions: 0644
            content: |
              apiVersion: v1
              kind: Pod
              metadata:
                name: kube-scheduler
                namespace: kube-system
              spec:
                hostNetwork: true
                containers:
                - name: kube-scheduler
                  image: quay.io/coreos/hyperkube:{{getenv "TAG"}}
                  command:
                  - /hyperkube
                  - scheduler
                  - --master=http://127.0.0.1:8080
                  - --leader-elect=true
                  livenessProbe:
                    httpGet:
                      host: 127.0.0.1
                      path: /healthz
                      port: 10251
                    initialDelaySeconds: 15
                    timeoutSeconds: 1

        runcmd:
          - set -x

          - cd /etc/systemd/system

          - systemctl daemon-reload
          - systemctl enable setup-etcd2-environment.service
          - systemctl enable setup-fleet-environment.service
          - systemctl enable etcd2.service
          - systemctl enable flannel.service
          - systemctl enable fleet.socket
          - systemctl enable fleet.service
          - systemctl enable skydns.service
          - systemctl enable jds_kafka.service
          - systemctl enable traefik.service

          - systemctl start setup-etcd2-environment.service
          - systemctl start etcd2.service

          - systemctl start flannel.service

          - systemctl start setup-fleet-environment.service
          - systemctl start fleet.service

          - systemctl start skydns.service

          - systemctl start jds_kafka.service


        final_message: "The system is finally up, after $UPTIME seconds"


parameters:
  key_name:
    type: string
    label: Name of keypair to assign to servers
    description: key_name=foo
    constraints:
      - custom_constraint: nova.keypair

  security_group:
    type: string

  network:
    type: string

  subnet:
    type: string

  image:
    type: string

  flavor:
    type: string

  anti_affinity:
    type: string

  instance_basename:
    type: string

  fleet_state:
    type: string

  etcd_initial_cluster:
    type: string
    description: "static0=http://192.168.1.10:2380,static1=http://192.168.1.11:2380,static2=http://192.168.1.12:2380"

  floatingip_network_name:
    type: string
    label: The Floating IP network for NAT
    description: floatingip_network_name=public